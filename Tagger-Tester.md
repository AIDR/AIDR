The tagger tester is a program that can be used after deploying the tagger, to test it independently of the other modules.

It requires both the **tagger stand-alone application** to be running, and the **aidr-tagger-api EE application** to be deployed (in the future, these will be a single EE application).

## Command line

The tagger tester is run through the following command:

```
mvn test -DtaggerTesterTest PARAMETERS
```

These parameters are optional:

```
-Dconfig=FILE
-Dnitems-train=NUMBER (default 200)
-Dnitems-test=NUMBER (default 1000)
-Dquiet=TRUE/FALSE (default false)
```

The _config_ is the name of the tagger configuration (or of a centralized configuration) to read properties that the tester needs to know to perform the testing.

The _nitems-train_ is the number of training (labelled) items to give to the tagger. It must be strictly larger than `sampleCountThreshold` which is the minimum number of items required to create a model.

The _nitems-test_ is the number of testing (unlabelled) items to give to the tagger. It can be any number greater than 1000. The reason why this cannot be a small number is to be able to have good statistics about the number of cases classified correctly and incorrectly.

The _quiet_ option suppresses the print of the tweets. All other messages are printed even in _quiet_ mode.

## Text of training/testing tweets

All tweets generated by this tester are synthetic and randomly generated, but conform to a specific format.

Half of the training tweets have the "WHITE" attribute value as a human-provided tag, and are made of random 10-word sequences of the words "light", "clear", "snow", "clouds", and "neutral".

Half of the training tweets have the "BLACK" attribute value as a human-provided tag, and are made of random 10-word sequences of the words "coal", "night", "coffee", "ink", and "neutral".

Example training tweets:

```
light clear neutral snow snow neutral clear light clear light -> WHITE
clear clouds snow light neutral snow clear clear light light -> WHITE
neutral neutral coffee coffee night coal night ink ink night -> BLACK
night coffee night coal coal ink night coffee neutral night -> BLACK
```

The testing tweets are generated in the same way, half of them correspond to "WHITE" tweets, half of them to "BLACK" tweets. Note that the testing items have no label associated to them, i.e. they are unlabelled.

The purpose of the "neutral" word is to have overlap, i.e. a word that appears in both the WHITE and BLACK sets, which avoids generating a trivial classification problem.

## Execution

The tagger tester should perform the following steps:

1. Make sure there is no data with `code="tagger_tester"` in case the tagger tester died abnormally in a previous run. If there is data, write a warning message, run the CLEANUP routine, and FAIL (forcing the user to run the tagger tester again).
1. Create a crisis (`name="Test Crisis", code="tagger_tester"`) using the `addCrisis` service in the `CrisisResource` of the Tagger-API module.
1. Create a classifier using the following steps:
 1. Create an attribute (name="tagger_tester_classifier") using the `NominalAttributeResource` in the Tagger-API module.
 1. Create three labels using the `NominalLabelResource` in the Tagger-API module (use `attribute_id` generated during the previous step)
   1. `name="White", code="white"`
    1. `name="Black", code="black"`
    1. `name="Does not apply" code="null"`
1. Create a ModelFamily using the `addCrisisAttribute` service of the `ModelFamilyResource` in the Tagger-API module (use `crisis_id`, `nominal_attribute_id` and `nominal_label_id` generated in the previous steps).
1. Subscribe to the REDIS queue where the tagger writes its output, otherwise FAIL.
1. Generate items using the 20 random words (defined above) and Push them to Redis on channel `FetcherChannel.tagger_tester` at the rate of 5 items/second. A valid AIDR item is a JSON document with minimum required field as [this](https://gist.github.com/imran15/4e4ce1948c2b82905c3e). You can add an additional JSON elements such as `item_id`, for example, to keep track of which item belongs to which label (i.e. White, Black). Keep pushing items until the document table in the `aidr-predict` database receives at least 200 items waiting to be labeled. (TODO: need an API to check the total number of unlabeled items for a crisis)
1. Get a task to label (to be described)
1. Send push notification to the tagger on each tagged item
1. Check if tagger has created a model (to be described)
1. Generate WHITE testing items and push them to the tagger **HOW?**
1. Verify that at least 80% of them are tagged WHITE, otherwise FAIL
1. Generate BLACK testing items and push them to the tagger **HOW?**
1. Verify that at least 80% of them are tagged BLACK, otherwise FAIL
1. Run a CLEANUP routine 
1. If this point is reached, exit with a successful return code

FAIL means printing a clear and informative message describing the condition and exiting with code 1 (non success).

CLEANUP means removing all data associated to `code="test_crisis"`

On interrupt by the user, the classifier tester should attempt to cleanup any state created in the classifier (**HOW?**).