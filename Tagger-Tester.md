The tagger tester is a program that can be used after deploying the tagger, to test it independently of the other modules.

It requires both the **tagger stand-alone application** to be running, and the **aidr-tagger-api, aidr-trainer-api, aidr-task-manager, aidr-db-manager EE applications** to be deployed.

## Command line

The tagger tester is run through the following command:

```
mvn test -DtaggerTesterTest PARAMETERS
```

These parameters are optional:

```
-Dconfig=FILE
-Dnitems-train=NUMBER (default 200)
-Dnitems-test=NUMBER (default 1000)
-Dquiet=TRUE/FALSE (default false)
```

The _config_ is the name of the tagger configuration (or of a centralized configuration) to read properties that the tester needs to know to perform the testing.

The _nitems-train_ is the number of training (labelled) items to give to the tagger. It must be strictly larger than `sampleCountThreshold` which is the minimum number of items required to create a model.

The _nitems-test_ is the number of testing (unlabelled) items to give to the tagger. It can be any number greater than 1000. The reason why this cannot be a small number is to be able to have good statistics about the number of cases classified correctly and incorrectly.

The _quiet_ option suppresses the print of the tweets. All other messages are printed even in _quiet_ mode.

## Text of training/testing tweets

All tweets generated by this tester are synthetic and randomly generated, but conform to a specific format.

Half of the training tweets have the "WHITE" attribute value as a human-provided tag, and are made of random 50-word sequences of the words "light", "clear", "snow", "clouds", "neutral", and "wNNNN". Whenever the word is wNNNN, it is written as a letter "w" followed by 4 random digits.

Half of the training tweets have the "BLACK" attribute value as a human-provided tag, and are made of random 50-word sequences of the words "coal", "night", "coffee", "ink", "neutral", and "wNNNN". Whenever the word is wNNNN, it is written as a letter "w" followed by 4 random digits.

Example training tweets:

```
light clear w0903 w1973 snow ... neutral clear light w8587 light -> WHITE
clear clouds snow light neutral ... w9451 clear clear light light -> WHITE
neutral neutral coffee w5871 night ... coal night w7510 ink night -> BLACK
w8250 coffee night coal w1211 ... ink night coffee neutral w7312 -> BLACK
```

The testing tweets are generated in the same way, half of them correspond to "WHITE" tweets, half of them to "BLACK" tweets. Note that the testing items have no label associated to them, i.e. they are unlabelled.

The purpose of the "neutral" word is to have overlap, i.e. a word that appears in both the WHITE and BLACK sets, which avoids generating a trivial classification problem. The purpose of the "wNNN" random words is to bypass the de-duplication check done by the tagger, ensuring every tweet is different enough from others.

## Execution

The tagger tester should perform the following steps:

1. Make sure there is no data with `code="tagger_tester"` in `aidr-pridict` database in case the tagger tester died abnormally in a previous run. If there is data, write a warning message, run the CLEANUP routine, and FAIL (forcing the user to run the tagger tester again)
1. Create a test user `Tagger Tester User` using the `addUser` service of the `UserResource` in the `Tagger-API` module. Check that the user exists after creating it. FAIL if this does not succeed.
1. Create a collection (`name="Tagger Tester Crisis", code="tagger_tester"`) using the `addCrisis` service in the `CrisisResource` of the Tagger-API module. Check that the collection exists after creating it. FAIL if this does not succeed.
1. Create a classifier using the following steps:
 1. Create an attribute (name="tagger_tester_classifier") using the `NominalAttributeResource` in the Tagger-API module. Check that the attribute exists after creating it. FAIL if this does not succeed.
 1. Create three labels using the `NominalLabelResource` in the Tagger-API module (use `attribute_id` generated during the previous step). Check that all labels exist after creating them. FAIL if this does not succeed.
    1. `name="White", code="white"`
    1. `name="Black", code="black"`
    1. `name="Does not apply" code="null"`
1. Create a ModelFamily using the `addCrisisAttribute` service of the `ModelFamilyResource` in the Tagger-API module (use `crisis_id`, `nominal_attribute_id` and `nominal_label_id` generated in the previous steps). Check that the model family exists after creating it. FAIL if this does not succeed.
1. Subscribe to the Redis queue where the tagger writes its output, otherwise FAIL
1. Generate random items (defined above) and Push them to Redis on channel `FetcherChannel.tagger_tester` at the rate of 5 items/second. A valid AIDR item is a JSON document with minimum required fields as defined [here](https://gist.github.com/imran15/4e4ce1948c2b82905c3e). You can add use the `tweetid` field, for example, to keep track of which item belongs to which label (i.e. White, Black). Keep pushing items until the document table in the `aidr-predict` database receives at least 200 items waiting to be labeled. (TO-DO: need an API to check the total number of unlabeled items for a crisis)
1. Get a task to label by using the `getOneTaskBufferToAssign` service of the `DocumentController` of the `Trainer-API` module 
1. Assign the correct label to that item (using its tweetid) and save it using the `save` service of the `TaskAnswerContoller` of the `Trainer-API` module
1. After about 100 white items and 100 black items have been tagged, check if the Tagger module has created a model using `(LATIKA: PLEASE ENTER API HERE)`. If not, wait 10 seconds and keep tagging more items, 50 at a time.
1. For testing, generate WHITE testing items and push them to the tagger
1. Subscribe to `REDIS_FOR_OUTPUT_QUEUE` 
1. Verify (reading from the `REDIS_FOR_OUTPUT_QUEUE`) that at least 80% of them are tagged WHITE, otherwise FAIL
1. Generate BLACK testing items and push them to the tagger
1. Verify  (reading from the `REDIS_FOR_OUTPUT_QUEUE`) that at least 80% of them are tagged BLACK, otherwise FAIL
1. Run a CLEANUP routine 
1. If this point is reached, exit with a successful return code

FAIL means executing the CLEANUP routine, printing a clear and informative message describing the condition, and exiting with code 1 (non success).

CLEANUP means removing all data associated to `code="tagger_tester"`

On interrupt by the user, the classifier tester should attempt to cleanup any state created in the classifier.